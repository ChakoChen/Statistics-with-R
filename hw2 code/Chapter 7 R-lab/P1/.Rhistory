berndtInvest = read.csv("berndtInvest.csv")
berndtInvest = read.csv("berndtInvest.csv")
Berndt = as.matrix(berndtInvest[, 2:5])
cov(Berndt)
cor(Berndt)
berndtInvest = read.csv("berndtInvest.csv")
Berndt = as.matrix(berndtInvest[, 2:5])
berndtInvest = read.csv("berndtInvest.csv")
Berndt = as.matrix(berndtInvest[, 2:5])
cov(Berndt)
cor(Berndt)
pairs(Berndt)
size(Berndt)
X1 = as.matrix(berndtInvest[,2])
X1 = as.matrix(berndtInvest[,2])
X = 0.5*X1 + 0.3*X2 + 0.2*X3
X1 = as.matrix(berndtInvest[,2])
X2 = as.matrix(berndtInvest[,3])
X3 = as.matrix(berndtInvest[,4])
X4 = as.matrix(berndtInvest[,5])
X = 0.5*X1 + 0.3*X2 + 0.2*X3
X = 0.5*X1 + 0.3*X2 + 0.2*X3
cov(X)
X = 0.5*X1 + 0.3*X2 + 0.2*X3
cov(t(X))
X = 0.5*X1 + 0.3*X2 + 0.2*X3
Xt = t(X)
Xt = t(X)
cov(X %*% Xt))
Xt = t(X)
cov(X %*% Xt)
cov(X %*% Xt)
dim(X)
dim(X)
dim(Xt)
cov(X %*% Xt)  #
cor(X %*% X)
X = 0.5*X1 + 0.3*X2 + 0.2*X3
Xt = t(X)      # transpose of X
Xvar = X %*% Xt
Xvar
View(Berndt)
View(Berndt)
View(X)
View(X)
Xt = t(X)       # transpose of X
cov(X,Xt)
Xt = t(X)       # transpose of X
cov(X,X)
Berndt = as.matrix(berndtInvest[, 2:5])
cov(Berndt)
library(MASS)  # needed for cov.trob
library(mnormt)  # needed for dmt
install.packages("mnormt")
library(MASS)  # needed for cov.trob
library(mnormt)  # needed for dmt
df = seq(2.5, 8, 0.01)
n = length(df)
loglik_profile = rep(0, n)
for(i in 1:n)
{
fit = cov.trob(Berndt, nu = df[i])
mu = as.vector(fit$center)
sigma = matrix(fit$cov, nrow = 4)
loglik_profile[i] = sum(log(dmt(Berndt, mean = fit$center,
S= f it$cov, df = df[i])))
}
for(i in 1:n)
{
fit = cov.trob(Berndt, nu = df[i])
mu = as.vector(fit$center)
sigma = matrix(fit$cov, nrow = 4)
loglik_profile[i] = sum(log(dmt(Berndt, mean = fit$center, S= f it$cov, df = df[i])))
}
loglik_profile = rep(0, n)
for(i in 1:n)
{
fit = cov.trob(Berndt, nu = df[i])
mu = as.vector(fit$center)
sigma = matrix(fit$cov, nrow = 4)
loglik_profile[i] = sum(log(dmt(Berndt, mean = fit$center, S= fit$cov, df = df[i])))
}
X = 0.5*X1 + 0.3*X2 + 0.2*X3
cov(X)
Berndt = as.matrix(berndtInvest[, 2:5])
C = cov(Berndt)
View(C)
View(C)
Xcov2 = C(1,1) + C(2,2) + C(3,3)
Xcov2 = C[1,1] + C[2,2] + C[3,3]
Xcov2
Xcov2 = 0.5^2*C[1,1] + 0.3^2*C[2,2] + 0.2^2*C[3,3]
Xcov2
Xcov2 = 0.5*0.5*C[1,1] + 0.3*0.3*C[2,2] + 0.2*0.2*C[3,3]
Xcov2
Xcov2/Xcov1
X = 0.5*X1 + 0.3*X2 + 0.2*X3
Xcov1 = cov(X) # 0.004408865
Xcov1
Xcov2/Xcov1
Xcov2 = 0.5^2*C[1,1] + 0.3^2*C[2,2] + 0.2^2*C[3,3] + 2*0.5*0.3*C[1,2] + 2*0.3*0.2*C[2,3] + 2*0.5*0.2*C[1,3]
Xcov2
Xcov1
if (Xcov2==Xcov1)
{
cat("Same value!")
}
if (Xcov2==Xcov1)
{
cat("Same value!")
}
cat("Same value!")
X = 0.5*X1 + 0.3*X2 + 0.2*X3
Xcov1 = cov(X) # 0.004408865
Xcov2 = 0.5^2*C[1,1] + 0.3^2*C[2,2] + 0.2^2*C[3,3] + 2*0.5*0.3*C[1,2] + 2*0.3*0.2*C[2,3] + 2*0.5*0.2*C[1,3]
if (Xcov2==Xcov1)
{
cat("Same value!")
}
w = matrix( c(0.5,0.3,0.2,0) )
S = as.matrix(cov(Berndt))
t(w) %*% (S %*% w)
source('ml_fit_multivariate_t.R')
result = ml_fit_multivariate_t(Berndt)
df = result$df_range           # extract results ...
max_index = result$max_index
loglik = result$logliks
if( FALSE ){
# Compute the derivative of the loglikelihood from the discrete samples evaluated above
#
h = df[2]-df[1]
d2_LL_nu2 = ( loglik[max_index+1] - 2*loglik[max_index] + loglik[max_index-1] ) / h^2
}else{
# Use the function fdHess in the nlme package to numerically evaluate the derivive of the loglikelihood:
#
library(nlme)
res = fdHess( df[max_index], function (x) loglik_fn(Berndt,x) )
d2_LL_nu2 = res$Hessian
}
s_nu = sqrt( 1/(-d2_LL_nu2) ) # the standard error in nu
alpha = 0.10
z_crit = qnorm( 1-0.5*alpha )
#if( save_plots ){ postscript("../../WriteUp/Graphics/Chapter7/chap_7_rlab_prob_1_ll_fn_of_dof.eps", onefile=FALSE, horizontal=FALSE) }
plot( df, loglik, type="l", cex.axis=1.5, cex.lab=1.5, ylab="loglikelihood", lwd=2 )
abline(h = max(loglik))
abline(v = df[max_index] - z_crit * s_nu)
abline(v = df[max_index] + z_crit * s_nu)
grid()
#if( save_plots ){ dev.off() }
install.packages("fEcofin")
library(MASS)
par(mfrow=c(1,4))
N = 2500
nu = 3
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(a)")
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(b)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(c)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(d)")
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 1000000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
library(mnormt)
data(CRSPday,package="Ecdat")
Y = CRSPday[,c(5,7)]
loglik = function(par){
mu = par[1:2]
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
scale_matrix = t(A) %*% A
df = par[6]
f = -sum(log(dmt(Y,mean=mu,S=scale_matrix,df=df)))
f
}
A = chol(cov(Y))
start = as.vector( c(apply(Y,2,mean),A[1,1],A[1,2],A[2,2],4) )
fit_mvt = optim( start, loglik, method="L-BFGS-B", lower=c(-0.02,-0.02,-0.1,-0.1,-0.1,2), upper=c(+0.02,+0.02,+0.1,+0.1,+0.1,15), hessian=T )
print(fit_mvt)
fit_mvt$par
fit_mvt$hessian
# Compute the inverse of the negative sample based Fisher information matrix using "solve"
inv_fisher = solve( fit_mvt$hessian, diag(length(fit_mvt$par)) )
# Extract the diagonal values and take the square root:
sqrt( diag(inv_fisher) )
par = fit_mvt$par
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
cov_matrix = t(A) %*% A
D = diag( c( sqrt( cov_matrix[1,1] ), sqrt( cov_matrix[2,2] ) ) )
DInv = solve( D, diag(2) )
cor_matrix = DInv %*% ( cov_matrix %*% DInv )
library("fEconfin")
t(w) %*% (S %*% w) # computes teh variance of the linear combination
berndtInvest = read.csv("berndtInvest.csv")
Berndt = as.matrix(berndtInvest[, 2:5])
C = cov(Berndt)
cor(Berndt)
pairs(Berndt)
w = matrix( c(0.5,0.3,0.2,0) )
S = as.matrix(cov(Berndt))
t(w) %*% (S %*% w) # computes teh variance of the linear combination
library(MASS)
par(mfrow=c(1,4))
N = 2500
nu = 3
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(a)")
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(b)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(c)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(d)")
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 1000000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
library(mnormt)
q
inds
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
q
library(mnormt)
data(CRSPday,package="Ecdat")
Y = CRSPday[,c(5,7)]
loglik = function(par){
mu = par[1:2]
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
scale_matrix = t(A) %*% A
df = par[6]
f = -sum(log(dmt(Y,mean=mu,S=scale_matrix,df=df)))
f
}
A = chol(cov(Y))
start = as.vector( c(apply(Y,2,mean),A[1,1],A[1,2],A[2,2],4) )
fit_mvt = optim( start, loglik, method="L-BFGS-B", lower=c(-0.02,-0.02,-0.1,-0.1,-0.1,2), upper=c(+0.02,+0.02,+0.1,+0.1,+0.1,15), hessian=T )
print(fit_mvt)
fit_mvt$par
fit_mvt$hessian
# Compute the inverse of the negative sample based Fisher information matrix using "solve"
inv_fisher = solve( fit_mvt$hessian, diag(length(fit_mvt$par)) )
# Extract the diagonal values and take the square root:
sqrt( diag(inv_fisher) )
par = fit_mvt$par
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
cov_matrix = t(A) %*% A
D = diag( c( sqrt( cov_matrix[1,1] ), sqrt( cov_matrix[2,2] ) ) )
DInv = solve( D, diag(2) )
cor_matrix = DInv %*% ( cov_matrix %*% DInv )
clear
clc
library(mnormt)
data(CRSPday,package="Ecdat")
Y = CRSPday[,c(5,7)]
loglik = function(par){
mu = par[1:2]
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
scale_matrix = t(A) %*% A
df = par[6]
f = -sum(log(dmt(Y,mean=mu,S=scale_matrix,df=df)))
f
}
A = chol(cov(Y))
start = as.vector( c(apply(Y,2,mean),A[1,1],A[1,2],A[2,2],4) )
fit_mvt = optim( start, loglik, method="L-BFGS-B", lower=c(-0.02,-0.02,-0.1,-0.1,-0.1,2), upper=c(+0.02,+0.02,+0.1,+0.1,+0.1,15), hessian=T )
print(fit_mvt)
fit_mvt$par
fit_mvt$hessian
inv_fisher = solve( fit_mvt$hessian, diag(length(fit_mvt$par)) )
sqrt( diag(inv_fisher) )
par = fit_mvt$par
A = matrix( c(par[3],par[4],0,par[5]), nrow=2, byrow=T )
cov_matrix = t(A) %*% A
D = diag( c( sqrt( cov_matrix[1,1] ), sqrt( cov_matrix[2,2] ) ) )
DInv = solve( D, diag(2) )
cor_matrix = DInv %*% ( cov_matrix %*% DInv )
cor_matrix
View(A)
View(A)
A
w1
w2
cor(w1,w2)
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(c)")
cor(w1,w2)
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(d)")
w
cor(w,w)
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(b)")
View(X)
View(X)
View(X)
w1
cor(w1, w2)
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 10000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
q
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 10000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 10000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 10000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
berndtInvest = read.csv("berndtInvest.csv")
Berndt = as.matrix(berndtInvest[, 2:5])
C = cov(Berndt)
cor(Berndt)
pairs(Berndt)
w = matrix( c(0.5,0.3,0.2,0) )
S = as.matrix(cov(Berndt))
t(w) %*% (S %*% w) # computes teh variance of the linear combination
source('ml_fit_multivariate_t.R')
result = ml_fit_multivariate_t(Berndt)
df = result$df_range           # extract results ...
max_index = result$max_index
loglik = result$logliks
if( FALSE ){
# Compute the derivative of the loglikelihood from the discrete samples evaluated above
#
h = df[2]-df[1]
d2_LL_nu2 = ( loglik[max_index+1] - 2*loglik[max_index] + loglik[max_index-1] ) / h^2
}else{
# Use the function fdHess in the nlme package to numerically evaluate the derivive of the loglikelihood:
#
library(nlme)
res = fdHess( df[max_index], function (x) loglik_fn(Berndt,x) )
d2_LL_nu2 = res$Hessian
}
s_nu = sqrt( 1/(-d2_LL_nu2) ) # the standard error in nu
alpha = 0.10
z_crit = qnorm( 1-0.5*alpha )
plot( df, loglik, type="l", cex.axis=1.5, cex.lab=1.5, ylab="loglikelihood", lwd=2 )
abline(h = max(loglik))
abline(v = df[max_index] - z_crit * s_nu)
abline(v = df[max_index] + z_crit * s_nu)
grid()
library(MASS)
par(mfrow=c(1,4))
N = 2500
nu = 3
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(a)")
set.seed(5640)
cov = matrix(c(1,0.8,0.8,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(b)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w1 = sqrt(nu/rchisq(N,df=nu))
w2 = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w1,w2)
plot(X,main="(c)")
set.seed(5640)
cov = matrix(c(1,0,0,1),nrow=2)
X = mvrnorm(N, mu=c(0,0), Sigma=cov)
w = sqrt(nu/rchisq(N,df=nu))
X = X * cbind(w,w)
plot(X,main="(d)")
alpha = 0.01
m = c(0.001,0.002)
Sgma = matrix( data=c( 0.1, 0.03, 0.03, 0.15 ), nrow=2, ncol=2, byrow=T )
df = 5
w = c(1/2,1/2)
nSamples = 10000
X = rmt( nSamples, m, S=Sgma )
Rs = X %*% w
q = quantile( Rs, 1-alpha ) # the 99% point
inds = Rs >= q
print( sprintf( "Using N= %10d has a mean of upper %10.6f quantile of= %10.6f", nSamples, 1-alpha, mean( Rs[inds] ) ) )
mean( Rs[inds] )
mean( Rs[inds] )
mean( Rs[inds] )
mean( Rs[inds] )
mean( Rs[inds] )
Rs(inds)
Rs[inds]
